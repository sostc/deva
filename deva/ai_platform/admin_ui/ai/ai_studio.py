#!/usr/bin/env python
# coding: utf-8
"""
Deva AI å·¥ä½œå®¤

æ•´åˆ AI ä»£ç ç”Ÿæˆå’Œåˆ›å»ºåŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„ AI è¾…åŠ©å¼€å‘ä½“éªŒã€‚

åŠŸèƒ½å±‚æ¬¡ï¼š
1. å¿«é€Ÿç”Ÿæˆ - ç®€å•ä»£ç ç‰‡æ®µï¼Œæ— éœ€é…ç½®
2. æ ‡å‡†åˆ›å»º - å¸¦é…ç½®çš„å®Œæ•´åˆ›å»ºæµç¨‹
3. é«˜çº§å®šåˆ¶ - è‡ªå®šä¹‰ä»£ç å’Œå‚æ•°
"""

from __future__ import annotations

import time
from typing import Dict, Any, List, Optional


# ============================================================================
# AI å·¥ä½œå®¤ä¸»ç•Œé¢
# ============================================================================

async def show_ai_studio(ctx):
    """æ˜¾ç¤º AI å·¥ä½œå®¤ä¸»ç•Œé¢ - ç®€åŒ–ç‰ˆ"""
    put_markdown = ctx['put_markdown']
    put_button = ctx['put_button']
    put_row = ctx['put_row']
    run_async = ctx['run_async']

    put_markdown("## ğŸ¤– AI å·¥ä½œå®¤")
    put_markdown("ä¸€ç«™å¼ AI è¾…åŠ©å¼€å‘å¹³å°ï¼Œä»ä»£ç ç”Ÿæˆåˆ°éƒ¨ç½²")

    # æ¨¡å‹è®¾ç½®åŒºåŸŸï¼ˆæ”¾åœ¨æœ€æ˜¾çœ¼çš„ä½ç½®ï¼‰
    with ctx['use_scope']('ai_model_settings'):
        await show_model_settings(ctx)

    put_markdown("---")

    # å¿«é€Ÿæ“ä½œåŒº
    put_markdown("### âš¡ å¿«é€Ÿæ“ä½œ")
    put_row([
        put_button('ğŸ’¬ å¯¹è¯ç”Ÿæˆä»£ç ', onclick=lambda: run_async(show_quick_chat_gen(ctx)), color='primary'),
        put_button('ğŸ“ ä»£ç ç‰‡æ®µç”Ÿæˆ', onclick=lambda: run_async(show_quick_code_gen(ctx)), color='info'),
        put_button('ğŸ”§ æ¨¡æ¿åˆ›å»º', onclick=lambda: run_async(show_template_creator(ctx)), color='success'),
    ])

    put_markdown("---")

    # ç›´æ¥æ˜¾ç¤ºåˆ›å»ºä¸­å¿ƒå†…å®¹
    run_async(show_creation_center(ctx))


async def show_model_settings(ctx):
    """æ˜¾ç¤ºæ¨¡å‹è®¾ç½® - ä»…æ˜¾ç¤ºå·²é…ç½®çš„æ¨¡å‹åˆ—è¡¨"""
    put_markdown = ctx['put_markdown']
    put_button = ctx['put_button']
    put_row = ctx['put_row']
    put_table = ctx['put_table']
    run_async = ctx['run_async']
    toast = ctx['toast']
    use_scope = ctx['use_scope']
    clear = ctx['clear']

    # ä»é…ç½®æ•°æ®åº“è¯»å–æ‰€æœ‰å·²é…ç½®çš„å¤§æ¨¡å‹
    available_models = get_available_models_from_config()
    
    if not available_models:
        return  # æ²¡æœ‰é…ç½®çš„æ¨¡å‹åˆ™ä¸æ˜¾ç¤º
    
    # è·å–å½“å‰é»˜è®¤æ¨¡å‹
    current_model = ctx.get('ai_default_model', '')
    if not current_model and available_models:
        current_model = available_models[0][0]
    
    # æ¨¡å‹æè¿°
    model_descriptions = {
        'deepseek': 'ğŸš€ DeepSeek - ä»£ç ç”Ÿæˆèƒ½åŠ›å¼º',
        'kimi': 'ğŸ’¬ Kimi - ä¸­æ–‡ç†è§£ä¼˜ç§€',
        'qwen': 'âš–ï¸ é€šä¹‰åƒé—® - ç»¼åˆèƒ½åŠ›å‡è¡¡',
        'baichuan': 'âš¡ ç™¾å· - å¿«é€Ÿå“åº”',
        'glm': 'ğŸ§  æ™ºè°± GLM - é•¿æ–‡æœ¬å¤„ç†',
        'minimax': 'ğŸ¯ MiniMax - å¤šåœºæ™¯é€‚ç”¨',
    }
    
    # æ˜¾ç¤ºæ‰€æœ‰å·²é…ç½®æ¨¡å‹åˆ—è¡¨
    put_markdown(f"**ğŸ“Š å·²é…ç½® {len(available_models)} ä¸ªå¤§æ¨¡å‹ï¼š**")
    
    model_table = [['æ¨¡å‹', 'çŠ¶æ€', 'å¿«æ·æ“ä½œ']]
    for model_id, config in available_models:
        is_default = 'âœ… é»˜è®¤' if model_id == current_model else 'â­•'
        model_table.append([
            model_descriptions.get(model_id, model_id),
            is_default,
            put_button('è®¾ä¸ºé»˜è®¤', 
                      onclick=lambda mid=model_id: run_async(switch_and_save_model(ctx, mid)),
                      color='text')
        ])
    
    put_table(model_table)
    
    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    current_desc = model_descriptions.get(current_model, current_model)
    put_markdown(f"> ğŸ“Œ å½“å‰ä»£ç ç”Ÿæˆé»˜è®¤æ¨¡å‹ï¼š**{current_model}** {current_desc}")


async def switch_and_save_model(ctx, model_id: str):
    """åˆ‡æ¢å¹¶ä¿å­˜æ¨¡å‹"""
    toast = ctx['toast']
    clear = ctx['clear']
    use_scope = ctx['use_scope']
    
    ctx['ai_default_model'] = model_id
    
    try:
        from deva.config import config
        config.set('ai.default_model', model_id)
        toast(f'âœ… å·²åˆ‡æ¢åˆ° {model_id}', color='success')
    except Exception as e:
        toast(f'ä¿å­˜å¤±è´¥ï¼š{e}', color='error')
    
    # åˆ·æ–°è®¾ç½®åŒºåŸŸ
    clear('ai_model_settings')
    with use_scope('ai_model_settings'):
        await show_model_settings(ctx)


async def refresh_model_status(ctx):
    """åˆ·æ–°æ¨¡å‹çŠ¶æ€"""
    toast = ctx['toast']
    clear = ctx['clear']
    use_scope = ctx['use_scope']
    
    current_model = ctx.get('ai_default_model', 'deepseek')
    toast(f'æ­£åœ¨åˆ·æ–° {current_model} çŠ¶æ€...', color='info')
    
    clear('ai_model_settings')
    with use_scope('ai_model_settings'):
        await show_model_settings(ctx)


def get_available_models_from_config() -> list:
    """ä»é…ç½®æ•°æ®åº“è¯»å–æ‰€æœ‰å·²é…ç½®çš„å¤§æ¨¡å‹"""
    available = []
    seen_keys = set()
    
    try:
        # æ–¹å¼ 1: ä» deva.config è¯»å–ï¼ˆé…ç½®æ¨¡å—ä½¿ç”¨çš„æ–¹å¼ï¼‰
        from deva.config import config
        
        # è·å–æ‰€æœ‰ LLM é…ç½®
        model_types = ['deepseek', 'kimi', 'qwen', 'baichuan', 'glm', 'minimax', 'sambanova']
        
        for model_type in model_types:
            model_config = config.get_llm_config(model_type)
            if model_config and model_config.get('api_key'):
                available.append((model_type, model_config))
                seen_keys.add(model_type)
    except Exception as e:
        print(f"ä» config è¯»å–å¤±è´¥ï¼š{e}")
    
    try:
        # æ–¹å¼ 2: ä» NB('llm_config') è¯»å–ï¼ˆå…¼å®¹æ—§é…ç½®ï¼‰
        from deva import NB
        llm_nb = NB('llm_config')
        
        for key, cfg in llm_nb.items():
            if isinstance(cfg, dict) and cfg.get('api_key'):
                # é¿å…é‡å¤
                if key not in seen_keys:
                    available.append((key, cfg))
    except Exception as e:
        print(f"ä» NB è¯»å–å¤±è´¥ï¼š{e}")
    
    return available


def get_model_status_info(ctx, model_type: str) -> dict:
    """è·å–æ¨¡å‹é…ç½®çŠ¶æ€"""
    try:
        # ä» config è¯»å–ï¼ˆä¸»è¦æ–¹å¼ï¼‰
        from deva.config import config
        model_config = config.get_llm_config(model_type)
        
        if model_config and model_config.get('api_key'):
            return {'ready': True, 'model_type': model_type, 'configured': True}
            
        return {'ready': False, 'model_type': model_type, 'configured': False}
    except Exception as e:
        print(f"è·å–æ¨¡å‹çŠ¶æ€å¤±è´¥ï¼š{e}")
        return {'ready': False, 'model_type': model_type, 'configured': False}


# ============================================================================
# å¿«é€Ÿç”Ÿæˆï¼ˆè½»é‡çº§ï¼‰
# ============================================================================

async def show_quick_chat_gen(ctx):
    """é€šè¿‡å¯¹è¯å¿«é€Ÿç”Ÿæˆä»£ç """
    put_markdown = ctx['put_markdown']
    input_comp = ctx['input']
    put_button = ctx['put_button']
    put_textarea = ctx['textarea']
    put_row = ctx['put_row']
    pin = ctx['pin']
    use_scope = ctx['use_scope']
    clear = ctx['clear']
    run_async = ctx['run_async']
    toast = ctx['toast']
    log = ctx.get('log')

    with ctx['popup']('å¯¹è¯ç”Ÿæˆä»£ç ', size='large', closable=True):
        put_markdown("### ğŸ’¬ å¯¹è¯ç”Ÿæˆä»£ç ")
        put_markdown("**æè¿°ä½ çš„éœ€æ±‚ï¼ŒAI ä¼šç”Ÿæˆå¯¹åº”ä»£ç ï¼š**")
        
        # ç¬¬ä¸€æ­¥ï¼šè¾“å…¥éœ€æ±‚
        with use_scope('chat_input_scope'):
            result = await ctx['input_group']('éœ€æ±‚', [
                input_comp('ä»£ç éœ€æ±‚', name='requirement', type='text',
                          placeholder='ä¾‹å¦‚ï¼šå†™ä¸€ä¸ªå‡½æ•°è®¡ç®—åˆ—è¡¨å¹³å‡å€¼', required=True),
                ctx['actions']('æ“ä½œ', [
                    {'label': 'ğŸ¤– ç”Ÿæˆ', 'value': 'generate'},
                ], name='action')
            ])

        if result.get('action') == 'generate':
            requirement = result['requirement']
            model_type = ctx.get('ai_default_model', 'deepseek')
            
            # æ‰“å°æ—¥å¿—
            if log:
                (f"[AI ä»£ç ç”Ÿæˆ] å¼€å§‹ç”Ÿæˆä»£ç ï¼Œæ¨¡å‹ï¼š{model_type}, éœ€æ±‚ï¼š{requirement[:50]}...") >> log
            
            # æ˜¾ç¤ºç”Ÿæˆä¸­
            clear('chat_input_scope')
            with use_scope('chat_input_scope'):
                put_markdown(f"*ğŸ¤– æ­£åœ¨ä½¿ç”¨ {model_type} ç”Ÿæˆä»£ç ...*")
            
            try:
                from deva.admin_ui.llm_service import get_gpt_response

                # æ‰“å°æ—¥å¿—
                if log:
                    (f"[AI ä»£ç ç”Ÿæˆ] æ­£åœ¨è°ƒç”¨ AI æœåŠ¡...") >> log

                # æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡
                from openai import AsyncOpenAI
                import requests
                
                # è·å– log å’Œ warn å¯¹è±¡ï¼Œå¹¶åˆ›å»ºæ”¯æŒ >> æ“ä½œçš„åŒ…è£…å™¨
                log_func = ctx.get('log')
                warn_func = ctx.get('warn', lambda x: print(f"[WARN] {x}"))
                
                # åˆ›å»ºæ”¯æŒ >> æ“ä½œçš„åŒ…è£…å™¨ï¼ˆæ¨¡æ‹Ÿ Deva Stream è¡Œä¸ºï¼‰
                class LogWrapper:
                    def __init__(self, func):
                        self.func = func if func else (lambda x: print(f"[LOG] {x}"))
                    def __rshift__(self, other):
                        # æ”¯æŒ stream >> func æ¨¡å¼
                        self.func(other)
                        return other
                    def __rrshift__(self, other):
                        # æ”¯æŒ str >> LogWrapper æ¨¡å¼
                        self.func(other)
                        return other
                    def __call__(self, msg):
                        # æ”¯æŒ func(msg) ç›´æ¥è°ƒç”¨
                        self.func(msg)
                        return msg
                
                llm_ctx = {
                    'NB': ctx.get('NB'),
                    'warn': LogWrapper(warn_func),
                    'log': LogWrapper(log_func),
                    'requests': requests,
                    'AsyncOpenAI': AsyncOpenAI,
                    'put_out': ctx.get('put_out'),
                    'toast': ctx.get('toast', lambda x, color='info': print(f"[TOAST] {x}")),
                    'run_ai_in_worker': ctx.get('run_ai_in_worker'),
                    'traceback': __import__('traceback'),
                }

                prompt = f"è¯·ç”Ÿæˆä»¥ä¸‹éœ€æ±‚çš„ Python ä»£ç ï¼Œåªè¿”å›ä»£ç ï¼Œä¸è¦è§£é‡Šï¼š{requirement}"
                code = await get_gpt_response(llm_ctx, prompt, model_type=model_type)

                # æ‰“å°æ—¥å¿—
                if log:
                    code_lines = len(code.split('\n'))
                    code_chars = len(code)
                    (f"[AI ä»£ç ç”Ÿæˆ] ä»£ç ç”ŸæˆæˆåŠŸï¼Œ{code_lines} è¡Œï¼Œ{code_chars} å­—ç¬¦") >> log

                # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç å’Œç¼–è¾‘çª—å£
                clear('chat_input_scope')
                with use_scope('chat_input_scope'):
                    put_markdown("### ğŸ“ ç”Ÿæˆçš„ä»£ç ")
                    put_markdown("**ğŸ’¡ æç¤ºï¼š** ä»£ç å·²ç”Ÿæˆï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†ä¸­ç›´æ¥ç¼–è¾‘ä¿®æ”¹")
                    
                    # ä½¿ç”¨ textarea æä¾›å¯ç¼–è¾‘çš„ä»£ç çª—å£
                    await put_textarea(
                        'generated_code',
                        value=code,
                        code={'mode': 'python', 'theme': 'darcula'},
                        rows=20,
                        placeholder='åœ¨æ­¤ç¼–è¾‘ä»£ç ...'
                    )
                    
                    put_markdown(f"> ğŸ¤– ä½¿ç”¨æ¨¡å‹ï¼š{model_type}")
                    
                    put_markdown("**ğŸ“‹ æ“ä½œï¼š**")
                    put_row([
                        put_button('ğŸ“‹ å¤åˆ¶ä»£ç ',
                                  onclick=lambda: run_async(copy_code_from_pin(ctx, 'generated_code')),
                                  color='primary'),
                        put_button('ğŸ’¾ ä¿å­˜åˆ°æ–‡ä»¶',
                                  onclick=lambda: run_async(save_code_to_file(ctx, 'generated_code')),
                                  color='success'),
                        put_button('ğŸ”„ é‡æ–°ç”Ÿæˆ',
                                  onclick=lambda: run_async(show_quick_chat_gen(ctx)),
                                  color='warning'),
                    ])
                
                toast('ä»£ç ç”ŸæˆæˆåŠŸ', color='success')
            except Exception as e:
                # æ‰“å°é”™è¯¯æ—¥å¿—
                if log:
                    import traceback
                    (f"[AI ä»£ç ç”Ÿæˆ] ç”Ÿæˆå¤±è´¥ï¼š{e}") >> log
                    traceback.format_exc() >> log
                
                clear('chat_input_scope')
                with use_scope('chat_input_scope'):
                    put_markdown(f"âŒ ç”Ÿæˆå¤±è´¥ï¼š{e}")
                toast(f'ç”Ÿæˆå¤±è´¥ï¼š{e}', color='error')


async def generate_code_simple(ctx, requirement: str):
    """ç®€å•ä»£ç ç”Ÿæˆ - å¸¦å¯ç¼–è¾‘çª—å£"""
    toast = ctx['toast']
    put_markdown = ctx['put_markdown']
    put_code = ctx['put_code']
    put_button = ctx['put_button']
    put_textarea = ctx['textarea']
    pin = ctx['pin']
    use_scope = ctx['use_scope']
    clear = ctx['clear']
    run_async = ctx['run_async']

    # è·å–é»˜è®¤æ¨¡å‹
    model_type = ctx.get('ai_default_model', 'deepseek')

    toast(f'æ­£åœ¨ä½¿ç”¨ {model_type} ç”Ÿæˆä»£ç ...', color='info')

    try:
        from deva.admin_ui.llm_service import get_gpt_response

        prompt = f"è¯·ç”Ÿæˆä»¥ä¸‹éœ€æ±‚çš„ Python ä»£ç ï¼Œåªè¿”å›ä»£ç ï¼Œä¸è¦è§£é‡Šï¼š{requirement}"
        code = await get_gpt_response(ctx, prompt, model_type=model_type)

        # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç å’Œç¼–è¾‘çª—å£
        with ctx['popup']('ç”Ÿæˆçš„ä»£ç ', size='large', closable=True):
            put_markdown("### ğŸ“ ç”Ÿæˆçš„ä»£ç ")
            put_markdown("**ğŸ’¡ æç¤ºï¼š** ä»£ç å·²ç”Ÿæˆï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†ä¸­ç›´æ¥ç¼–è¾‘ä¿®æ”¹")
            
            # ä½¿ç”¨ textarea æä¾›å¯ç¼–è¾‘çš„ä»£ç çª—å£
            with use_scope('code_editor_scope'):
                await put_textarea(
                    'generated_code',
                    value=code,
                    code={'mode': 'python', 'theme': 'darcula'},
                    rows=20,
                    placeholder='åœ¨æ­¤ç¼–è¾‘ä»£ç ...'
                )
            
            put_markdown(f"> ğŸ¤– ä½¿ç”¨æ¨¡å‹ï¼š{model_type}")
            
            put_markdown("**ğŸ“‹ æ“ä½œï¼š**")
            put_button('ğŸ“‹ å¤åˆ¶ä»£ç ',
                      onclick=lambda: run_async(copy_code_from_pin(ctx, 'generated_code')),
                      color='primary')
            put_button('ğŸ’¾ ä¿å­˜åˆ°æ–‡ä»¶',
                      onclick=lambda: run_async(save_code_to_file(ctx, 'generated_code')),
                      color='success')
            put_button('ğŸ”„ é‡æ–°ç”Ÿæˆ',
                      onclick=lambda: run_async(regenerate_code(ctx, requirement)),
                      color='warning')

        toast('ä»£ç ç”ŸæˆæˆåŠŸ', color='success')
    except Exception as e:
        toast(f'ç”Ÿæˆå¤±è´¥ï¼š{e}', color='error')


async def copy_code_from_pin(ctx, pin_name: str):
    """ä» pin ç»„ä»¶å¤åˆ¶ä»£ç """
    code = await ctx['pin'][pin_name]
    await ctx['run_js'](f"navigator.clipboard.writeText(`{code}`)")
    ctx['toast']('ä»£ç å·²å¤åˆ¶åˆ°å‰ªè´´æ¿', color='success')


async def save_code_to_file(ctx, pin_name: str):
    """ä¿å­˜ä»£ç åˆ°æ–‡ä»¶"""
    code = await ctx['pin'][pin_name]
    
    # è·å–æ–‡ä»¶å
    filename = await ctx['input']('æ–‡ä»¶å', type='text', value='generated_code.py')
    
    if filename:
        try:
            from deva import write_to_file
            code >> write_to_file(filename)
            ctx['toast'](f'ä»£ç å·²ä¿å­˜åˆ° {filename}', color='success')
        except Exception as e:
            ctx['toast'](f'ä¿å­˜å¤±è´¥ï¼š{e}', color='error')


async def regenerate_code(ctx, requirement: str):
    """é‡æ–°ç”Ÿæˆä»£ç """
    ctx['clear']('code_editor_scope')
    await generate_code_simple(ctx, requirement)


async def show_quick_code_gen(ctx):
    """å¿«é€Ÿä»£ç ç‰‡æ®µç”Ÿæˆ"""
    put_markdown = ctx['put_markdown']
    put_button = ctx['put_button']
    put_row = ctx['put_row']
    run_async = ctx['run_async']

    with ctx['popup']('ä»£ç ç‰‡æ®µç”Ÿæˆ', size='large', closable=True):
        put_markdown("### ğŸ“ ä»£ç ç‰‡æ®µç”Ÿæˆ")
        put_markdown("**é€‰æ‹©ä»£ç ç±»å‹ï¼š**")

        put_row([
            put_button('ğŸ Python å‡½æ•°', onclick=lambda: run_async(show_quick_python_gen(ctx)), color='info'),
            put_button('ğŸ“Š Deva ç»„ä»¶', onclick=lambda: run_async(show_quick_deva_gen(ctx)), color='info'),
        ])


async def show_quick_python_gen(ctx):
    """å¿«é€Ÿ Python å‡½æ•°ç”Ÿæˆ"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']

    with ctx['popup']('ç”Ÿæˆ Python å‡½æ•°', size='large', closable=True):
        put_markdown("### ğŸ Python å‡½æ•°ç”Ÿæˆ")
        put_markdown("**ç¤ºä¾‹ï¼š**")
        put_markdown("- è®¡ç®—åˆ—è¡¨å¹³å‡å€¼")
        put_markdown("- å®ç°å•ä¾‹æ¨¡å¼")
        put_markdown("- è£…é¥°å™¨è®¡ç®—æ‰§è¡Œæ—¶é—´")

        result = await ctx['input_group']('éœ€æ±‚', [
            textarea('å‡½æ•°æè¿°', name='description', required=True,
                    placeholder='æè¿°å‡½æ•°åŠŸèƒ½...', rows=4),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– ç”Ÿæˆ', 'value': 'generate'},
            ], name='action')
        ])

        if result.get('action') == 'generate':
            await generate_code_simple(ctx, f"Python å‡½æ•°ï¼š{result['description']}")


async def show_quick_deva_gen(ctx):
    """å¿«é€Ÿ Deva ç»„ä»¶ç”Ÿæˆ"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']

    with ctx['popup']('ç”Ÿæˆ Deva ç»„ä»¶', size='large', closable=True):
        put_markdown("### ğŸ“Š Deva ç»„ä»¶ç”Ÿæˆ")
        put_markdown("**ç¤ºä¾‹ï¼š**")
        put_markdown("- ç®€å•çš„æ•°æ®è¿‡æ»¤ Pipe")
        put_markdown("- æ•°æ®è½¬æ¢ Lambda")
        put_markdown("- Stream å¤„ç†å‡½æ•°")

        result = await ctx['input_group']('éœ€æ±‚', [
            textarea('ç»„ä»¶æè¿°', name='description', required=True,
                    placeholder='æè¿°ç»„ä»¶åŠŸèƒ½...', rows=4),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– ç”Ÿæˆ', 'value': 'generate'},
            ], name='action')
        ])

        if result.get('action') == 'generate':
            await generate_code_simple(ctx, f"Deva ç»„ä»¶ï¼š{result['description']}")


# ============================================================================
# åˆ›å»ºä¸­å¿ƒï¼ˆå®Œæ•´æµç¨‹ï¼‰
# ============================================================================

async def show_creation_center(ctx):
    """æ˜¾ç¤ºåˆ›å»ºä¸­å¿ƒ"""
    put_markdown = ctx['put_markdown']
    put_button = ctx['put_button']
    put_row = ctx['put_row']
    run_async = ctx['run_async']

    put_markdown("### ğŸ“¦ åˆ›å»ºä¸­å¿ƒ")
    put_markdown("åˆ›å»ºå®Œæ•´çš„æ•°æ®æºã€ç­–ç•¥ã€ä»»åŠ¡ç­‰ Deva ç»„ä»¶")

    put_markdown("**é€‰æ‹©åˆ›å»ºç±»å‹ï¼š**")
    put_row([
        put_button('ğŸ“ˆ åˆ›å»ºæ•°æ®æº', onclick=lambda: run_async(show_datasource_creator(ctx)), color='success'),
        put_button('ğŸ“Š åˆ›å»ºç­–ç•¥', onclick=lambda: run_async(show_strategy_creator(ctx)), color='primary'),
        put_button('âš™ï¸ åˆ›å»ºä»»åŠ¡', onclick=lambda: run_async(show_task_creator(ctx)), color='warning'),
        put_button('ğŸ”§ è‡ªå®šä¹‰ç»„ä»¶', onclick=lambda: run_async(show_custom_component_creator(ctx)), color='info'),
    ])

    put_markdown("---")
    put_markdown("#### ğŸ’¡ åˆ›å»ºæµç¨‹è¯´æ˜")
    put_markdown("""
    1. **é€‰æ‹©ç±»å‹** - é€‰æ‹©è¦åˆ›å»ºçš„ç»„ä»¶ç±»å‹
    2. **é…ç½®å‚æ•°** - å¡«å†™åç§°ã€æè¿°ã€å‚æ•°ç­‰
    3. **AI ç”Ÿæˆä»£ç ** - AI æ ¹æ®é…ç½®ç”Ÿæˆå®Œæ•´ä»£ç 
    4. **é¢„è§ˆè°ƒæ•´** - æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç ï¼Œå¯é€‰æ‹©è°ƒæ•´
    5. **ä¿å­˜éƒ¨ç½²** - ä¿å­˜åˆ°æ•°æ®åº“å¹¶éƒ¨ç½²ä½¿ç”¨
    """)


async def show_custom_component_creator(ctx):
    """è‡ªå®šä¹‰ç»„ä»¶åˆ›å»ºå™¨"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']
    radio = ctx['radio']

    with ctx['popup']('åˆ›å»ºè‡ªå®šä¹‰ç»„ä»¶', size='large', closable=True):
        put_markdown("### ğŸ”§ è‡ªå®šä¹‰ç»„ä»¶åˆ›å»º")

        put_markdown("**é€‰æ‹©ç»„ä»¶ç±»å‹ï¼š**")
        component_type = await radio('ç»„ä»¶ç±»å‹', options=[
            ('stream', 'Stream æµ'),
            ('pipe', 'Pipe ç®¡é“'),
            ('processor', 'Processor å¤„ç†å™¨'),
            ('other', 'å…¶ä»–'),
        ], name='component_type', required=True)

        put_markdown("**æè¿°ç»„ä»¶åŠŸèƒ½ï¼š**")
        config = await ctx['input_group']('é…ç½®', [
            textarea('ç»„ä»¶æè¿°', name='description', required=True,
                    placeholder='è¯¦ç»†æè¿°ç»„ä»¶åŠŸèƒ½...', rows=6),
            ctx['input']('ç»„ä»¶åç§°', name='name', type='text',
                        placeholder='ä¾‹å¦‚ï¼šæ•°æ®è¿‡æ»¤å™¨', required=True),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– AI ç”Ÿæˆ', 'value': 'generate'},
            ], name='action')
        ])

        if config.get('action') == 'generate':
            await generate_component_code(ctx, config, component_type)


async def generate_component_code(ctx, config: dict, component_type: str):
    """ç”Ÿæˆç»„ä»¶ä»£ç """
    toast = ctx['toast']
    put_markdown = ctx['put_markdown']
    put_code = ctx['put_code']
    put_button = ctx['put_button']

    toast('æ­£åœ¨ç”Ÿæˆç»„ä»¶ä»£ç ...', color='info')

    try:
        from deva.admin_ui.llm_service import get_gpt_response

        type_map = {
            'stream': 'Deva Stream æµå¤„ç†ç»„ä»¶',
            'pipe': 'Deva Pipe æ•°æ®ç®¡é“ç»„ä»¶',
            'processor': 'Deva Processor æ•°æ®å¤„ç†ç»„ä»¶',
            'other': 'Deva ç»„ä»¶',
        }

        prompt = f"""
        åˆ›å»ºä¸€ä¸ª{type_map.get(component_type, 'Deva')}ä»£ç ï¼Œè¦æ±‚ï¼š
        - åç§°ï¼š{config.get('name', 'MyComponent')}
        - åŠŸèƒ½ï¼š{config.get('description', 'å¤„ç†æ•°æ®')}

        ä»£ç è¦æ±‚ï¼š
        1. ä½¿ç”¨ Deva æ¡†æ¶è§„èŒƒ
        2. æ·»åŠ è¯¦ç»†æ³¨é‡Š
        3. åŒ…å«é”™è¯¯å¤„ç†
        4. åªè¿”å› Python ä»£ç 
        """

        code = await get_gpt_response(ctx, prompt, model_type='deepseek')

        with ctx['popup']('ç”Ÿæˆçš„ç»„ä»¶ä»£ç ', size='large', closable=True):
            put_markdown(f"### ğŸ”§ ç»„ä»¶ä»£ç  - {config.get('name', 'Component')}")
            put_code(code)
            put_button('ğŸ“‹ å¤åˆ¶ä»£ç ',
                      onclick=lambda: ctx['run_js'](f"navigator.clipboard.writeText(`{code}`)"),
                      color='primary')

        toast('ç»„ä»¶ä»£ç ç”ŸæˆæˆåŠŸ', color='success')
    except Exception as e:
        toast(f'ç”Ÿæˆå¤±è´¥ï¼š{e}', color='error')


# ============================================================================
# ç”Ÿæˆä¸­å¿ƒï¼ˆä»£ç ç‰‡æ®µï¼‰
# ============================================================================

async def show_generation_center(ctx):
    """æ˜¾ç¤ºç”Ÿæˆä¸­å¿ƒ"""
    put_markdown = ctx['put_markdown']
    put_button = ctx['put_button']
    put_row = ctx['put_row']
    run_async = ctx['run_async']

    put_markdown("### âœ¨ ç”Ÿæˆä¸­å¿ƒ")
    put_markdown("å¿«é€Ÿç”Ÿæˆä»£ç ç‰‡æ®µï¼Œæ— éœ€å¤æ‚é…ç½®")

    put_markdown("**é€‰æ‹©ç”Ÿæˆç±»å‹ï¼š**")
    put_row([
        put_button('ğŸ Python ä»£ç ', onclick=lambda: run_async(show_python_code_gen(ctx)), color='info'),
        put_button('ğŸ“Š Deva ç­–ç•¥', onclick=lambda: run_async(show_deva_strategy_gen(ctx)), color='primary'),
        put_button('ğŸ“ˆ Deva æ•°æ®æº', onclick=lambda: run_async(show_deva_datasource_gen(ctx)), color='success'),
        put_button('âš™ï¸ Deva ä»»åŠ¡', onclick=lambda: run_async(show_deva_task_gen(ctx)), color='warning'),
    ])


# ä»åŸæœ‰ä»£ç ç”Ÿæˆå™¨å¯¼å…¥
async def show_python_code_gen(ctx):
    """æ˜¾ç¤º Python ä»£ç ç”Ÿæˆç•Œé¢"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']

    with ctx['popup']('ç”Ÿæˆ Python ä»£ç ', size='large', closable=True):
        put_markdown("### ğŸ“ ç”Ÿæˆ Python ä»£ç ")

        put_markdown("""
        **è¾“å…¥ä½ çš„éœ€æ±‚ï¼ŒAI ä¼šç”Ÿæˆå¯¹åº”çš„ Python ä»£ç ï¼š**

        ç¤ºä¾‹ï¼š
        - "å†™ä¸€ä¸ªå‡½æ•°ï¼Œè®¡ç®—åˆ—è¡¨ä¸­æ‰€æœ‰æ•°å­—çš„å¹³å‡å€¼"
        - "å†™ä¸€ä¸ªç±»ï¼Œå®ç°å•ä¾‹æ¨¡å¼"
        - "å†™ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºè®¡ç®—å‡½æ•°æ‰§è¡Œæ—¶é—´"
        """)

        requirement = await ctx['input_group']('ä»£ç éœ€æ±‚', [
            textarea('éœ€æ±‚æè¿°', name='description', required=True,
                    placeholder='è¯¦ç»†æè¿°ä½ æƒ³è¦çš„ä»£ç åŠŸèƒ½...', rows=5),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– ç”Ÿæˆä»£ç ', 'value': 'generate'},
                {'label': 'âŒ å–æ¶ˆ', 'value': 'cancel'}
            ], name='action')
        ])

        if requirement['action'] == 'generate':
            await generate_code(ctx, requirement['description'], 'python')


async def generate_code(ctx, prompt: str, code_type: str):
    """ç”Ÿæˆä»£ç  - å¸¦å¯ç¼–è¾‘çª—å£å’Œæ—¥å¿—"""
    toast = ctx['toast']
    put_markdown = ctx['put_markdown']
    put_textarea = ctx['textarea']
    put_button = ctx['put_button']
    pin = ctx['pin']
    use_scope = ctx['use_scope']
    clear = ctx['clear']
    run_async = ctx['run_async']
    log = ctx.get('log')

    # è·å–é»˜è®¤æ¨¡å‹
    model_type = ctx.get('ai_default_model', 'deepseek')

    # æ‰“å°æ—¥å¿—
    if log:
        (f"[AI ä»£ç ç”Ÿæˆ] å¼€å§‹ç”Ÿæˆä»£ç ï¼Œæ¨¡å‹ï¼š{model_type}, ç±»å‹ï¼š{code_type}") >> log

    toast(f'æ­£åœ¨ä½¿ç”¨ {model_type} ç”Ÿæˆä»£ç ...', color='info')

    try:
        from deva.admin_ui.llm_service import get_gpt_response

        # æ‰“å°æ—¥å¿—
        if log:
            (f"[AI ä»£ç ç”Ÿæˆ] æ­£åœ¨è°ƒç”¨ AI æœåŠ¡...") >> log

        # æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡
        from openai import AsyncOpenAI
        import requests
        
        # è·å– log å’Œ warn å¯¹è±¡ï¼Œå¹¶åˆ›å»ºæ”¯æŒ >> æ“ä½œçš„åŒ…è£…å™¨
        log_func = ctx.get('log')
        warn_func = ctx.get('warn', lambda x: print(f"[WARN] {x}"))
        
        # åˆ›å»ºæ”¯æŒ >> æ“ä½œçš„åŒ…è£…å™¨ï¼ˆæ¨¡æ‹Ÿ Deva Stream è¡Œä¸ºï¼‰
        class LogWrapper:
            def __init__(self, func):
                self.func = func if func else (lambda x: print(f"[LOG] {x}"))
            def __rshift__(self, other):
                # æ”¯æŒ stream >> func æ¨¡å¼
                self.func(other)
                return other
            def __rrshift__(self, other):
                # æ”¯æŒ str >> LogWrapper æ¨¡å¼
                self.func(other)
                return other
            def __call__(self, msg):
                # æ”¯æŒ func(msg) ç›´æ¥è°ƒç”¨
                self.func(msg)
                return msg
        
        llm_ctx = {
            'NB': ctx.get('NB'),
            'warn': LogWrapper(warn_func),
            'log': LogWrapper(log_func),
            'requests': requests,
            'AsyncOpenAI': AsyncOpenAI,
            'put_out': ctx.get('put_out'),
            'toast': ctx.get('toast', lambda x, color='info': print(f"[TOAST] {x}")),
            'run_ai_in_worker': ctx.get('run_ai_in_worker'),
            'traceback': __import__('traceback'),
        }

        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Python å¼€å‘è€…ï¼Œè¯·ç”Ÿæˆé«˜è´¨é‡ã€å¯è¿è¡Œçš„ä»£ç ã€‚åªè¿”å›ä»£ç ï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚"
        full_prompt = f"{system_prompt}\n\n{prompt}"

        code = await get_gpt_response(llm_ctx, full_prompt, model_type=model_type)

        # æ‰“å°æ—¥å¿—
        if log:
            code_lines = len(code.split('\n'))
            code_chars = len(code)
            (f"[AI ä»£ç ç”Ÿæˆ] ä»£ç ç”ŸæˆæˆåŠŸï¼Œ{code_lines} è¡Œï¼Œ{code_chars} å­—ç¬¦") >> log

        # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç å’Œç¼–è¾‘çª—å£
        with ctx['popup']('ç”Ÿæˆçš„ä»£ç ', size='large', closable=True):
            put_markdown("### ğŸ“ ç”Ÿæˆçš„ä»£ç ")
            put_markdown("**ğŸ’¡ æç¤ºï¼š** ä»£ç å·²ç”Ÿæˆï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†ä¸­ç›´æ¥ç¼–è¾‘ä¿®æ”¹")
            
            # ä½¿ç”¨ textarea æä¾›å¯ç¼–è¾‘çš„ä»£ç çª—å£
            with use_scope('code_editor_scope'):
                await put_textarea(
                    'generated_code',
                    value=code,
                    code={'mode': 'python', 'theme': 'darcula'},
                    rows=20,
                    placeholder='åœ¨æ­¤ç¼–è¾‘ä»£ç ...'
                )
            
            put_markdown(f"> ğŸ¤– ä½¿ç”¨æ¨¡å‹ï¼š{model_type}")
            
            put_markdown("**ğŸ“‹ æ“ä½œï¼š**")
            put_button('ğŸ“‹ å¤åˆ¶ä»£ç ',
                      onclick=lambda: run_async(copy_code_from_pin(ctx, 'generated_code')),
                      color='primary')
            put_button('ğŸ’¾ ä¿å­˜åˆ°æ–‡ä»¶',
                      onclick=lambda: run_async(save_code_to_file(ctx, 'generated_code')),
                      color='success')
            put_button('ğŸ”„ é‡æ–°ç”Ÿæˆ',
                      onclick=lambda: run_async(regenerate_code(ctx, full_prompt)),
                      color='warning')

        toast('ä»£ç ç”ŸæˆæˆåŠŸ', color='success')
    except Exception as e:
        # æ‰“å°é”™è¯¯æ—¥å¿—
        if log:
            import traceback
            (f"[AI ä»£ç ç”Ÿæˆ] ç”Ÿæˆå¤±è´¥ï¼š{e}") >> log
            traceback.format_exc() >> log
        
        toast(f'ç”Ÿæˆå¤±è´¥ï¼š{e}', color='error')


async def show_deva_strategy_gen(ctx):
    """æ˜¾ç¤º Deva ç­–ç•¥ä»£ç ç”Ÿæˆ"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']

    with ctx['popup']('ç”Ÿæˆ Deva ç­–ç•¥', size='large', closable=True):
        put_markdown("### ğŸ“Š ç”Ÿæˆ Deva é‡åŒ–ç­–ç•¥")

        put_markdown("""
        **è¾“å…¥ç­–ç•¥é€»è¾‘ï¼ŒAI ä¼šç”Ÿæˆ Deva ç­–ç•¥ä»£ç ï¼š**

        ç¤ºä¾‹ï¼š
        - "åŒå‡çº¿ç­–ç•¥ï¼šå½“ 5 æ—¥å‡çº¿ä¸Šç©¿ 20 æ—¥å‡çº¿æ—¶ä¹°å…¥ï¼Œä¸‹ç©¿æ—¶å–å‡º"
        - "MACD ç­–ç•¥ï¼šå½“ MACD é‡‘å‰æ—¶ä¹°å…¥ï¼Œæ­»å‰æ—¶å–å‡º"
        """)

        requirement = await ctx['input_group']('ç­–ç•¥éœ€æ±‚', [
            textarea('ç­–ç•¥æè¿°', name='description', required=True,
                    placeholder='è¯¦ç»†æè¿°ç­–ç•¥é€»è¾‘...', rows=5),
            ctx['input']('ç­–ç•¥åç§°', name='name', type='text',
                        placeholder='ä¾‹å¦‚ï¼šåŒå‡çº¿ç­–ç•¥', required=True),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– ç”Ÿæˆä»£ç ', 'value': 'generate'},
                {'label': 'âŒ å–æ¶ˆ', 'value': 'cancel'}
            ], name='action')
        ])

        if requirement['action'] == 'generate':
            prompt = f"ç”Ÿæˆä¸€ä¸ª Deva é‡åŒ–ç­–ç•¥ä»£ç ï¼Œç­–ç•¥åç§°ï¼š{requirement['name']}ï¼Œç­–ç•¥é€»è¾‘ï¼š{requirement['description']}ã€‚è¦æ±‚ä½¿ç”¨ StrategyUnit ç±»ï¼Œå®ç° process æ–¹æ³•ã€‚"
            await generate_code(ctx, prompt, 'deva_strategy')


async def show_deva_datasource_gen(ctx):
    """æ˜¾ç¤º Deva æ•°æ®æºä»£ç ç”Ÿæˆ"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']

    with ctx['popup']('ç”Ÿæˆ Deva æ•°æ®æº', size='large', closable=True):
        put_markdown("### ğŸ“ˆ ç”Ÿæˆ Deva æ•°æ®æº")

        put_markdown("""
        **è¾“å…¥æ•°æ®æºéœ€æ±‚ï¼ŒAI ä¼šç”Ÿæˆ Deva æ•°æ®æºä»£ç ï¼š**

        ç¤ºä¾‹ï¼š
        - "ä» Yahoo Finance è·å–è‚¡ç¥¨å®æ—¶æ•°æ®ï¼Œæ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡"
        - "è¯»å–æœ¬åœ° CSV æ–‡ä»¶ï¼Œè§£æä¸ºå­—å…¸æ ¼å¼"
        """)

        requirement = await ctx['input_group']('æ•°æ®æºéœ€æ±‚', [
            textarea('æ•°æ®æºæè¿°', name='description', required=True,
                    placeholder='è¯¦ç»†æè¿°æ•°æ®æºåŠŸèƒ½...', rows=5),
            ctx['input']('æ•°æ®æºåç§°', name='name', type='text',
                        placeholder='ä¾‹å¦‚ï¼šè‚¡ç¥¨æ•°æ®æº', required=True),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– ç”Ÿæˆä»£ç ', 'value': 'generate'},
                {'label': 'âŒ å–æ¶ˆ', 'value': 'cancel'}
            ], name='action')
        ])

        if requirement['action'] == 'generate':
            prompt = f"ç”Ÿæˆä¸€ä¸ª Deva æ•°æ®æºä»£ç ï¼Œæ•°æ®æºåç§°ï¼š{requirement['name']}ï¼ŒåŠŸèƒ½æè¿°ï¼š{requirement['description']}ã€‚è¦æ±‚ä½¿ç”¨ DataSource ç±»ï¼Œå®ç° fetch_data æ–¹æ³•ã€‚"
            await generate_code(ctx, prompt, 'deva_datasource')


async def show_deva_task_gen(ctx):
    """æ˜¾ç¤º Deva ä»»åŠ¡ä»£ç ç”Ÿæˆ"""
    put_markdown = ctx['put_markdown']
    textarea = ctx['textarea']

    with ctx['popup']('ç”Ÿæˆ Deva ä»»åŠ¡', size='large', closable=True):
        put_markdown("### âš™ï¸ ç”Ÿæˆ Deva ä»»åŠ¡")

        put_markdown("""
        **è¾“å…¥ä»»åŠ¡éœ€æ±‚ï¼ŒAI ä¼šç”Ÿæˆ Deva ä»»åŠ¡ä»£ç ï¼š**

        ç¤ºä¾‹ï¼š
        - "æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½æ•°æ®åº“"
        - "æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ç³»ç»ŸçŠ¶æ€ï¼Œå¼‚å¸¸æ—¶å‘é€å‘Šè­¦"
        """)

        requirement = await ctx['input_group']('ä»»åŠ¡éœ€æ±‚', [
            textarea('ä»»åŠ¡æè¿°', name='description', required=True,
                    placeholder='è¯¦ç»†æè¿°ä»»åŠ¡åŠŸèƒ½...', rows=5),
            ctx['input']('ä»»åŠ¡åç§°', name='name', type='text',
                        placeholder='ä¾‹å¦‚ï¼šæ•°æ®åº“å¤‡ä»½', required=True),
            ctx['input']('æ‰§è¡Œæ—¶é—´', name='schedule', type='text',
                        placeholder='ä¾‹å¦‚ï¼šæ¯å¤© 02:00', required=True),
            ctx['actions']('æ“ä½œ', [
                {'label': 'ğŸ¤– ç”Ÿæˆä»£ç ', 'value': 'generate'},
                {'label': 'âŒ å–æ¶ˆ', 'value': 'cancel'}
            ], name='action')
        ])

        if requirement['action'] == 'generate':
            prompt = f"ç”Ÿæˆä¸€ä¸ª Deva ä»»åŠ¡ä»£ç ï¼Œä»»åŠ¡åç§°ï¼š{requirement['name']}ï¼ŒåŠŸèƒ½æè¿°ï¼š{requirement['description']}ï¼Œæ‰§è¡Œæ—¶é—´ï¼š{requirement['schedule']}ã€‚è¦æ±‚ä½¿ç”¨å¼‚æ­¥å‡½æ•°å®ç°ã€‚"
            await generate_code(ctx, prompt, 'deva_task')


# ============================================================================
# åˆ›å»ºå†å²
# ============================================================================

async def show_creation_history(ctx):
    """æ˜¾ç¤ºåˆ›å»ºå†å²"""
    put_markdown = ctx['put_markdown']
    put_table = ctx['put_table']

    put_markdown("### ğŸ“‹ åˆ›å»ºå†å²")
    put_markdown("æŸ¥çœ‹æœ€è¿‘åˆ›å»ºçš„é¡¹ç›®")

    creations = ctx.get('recent_creations', [])
    if not creations:
        put_markdown("*æš‚æ— åˆ›å»ºè®°å½•*")
        return

    # å€’åºæ˜¾ç¤ºï¼Œæœ€æ–°çš„åœ¨å‰
    creations = list(reversed(creations[-20:]))

    table_data = [['ç±»å‹', 'åç§°', 'åˆ›å»ºæ—¶é—´', 'çŠ¶æ€', 'ä¿å­˜']]
    for item in creations:
        status_icon = 'âœ…' if item.get('status') == 'success' else 'âŒ'
        saved_icon = 'ğŸ’¾' if item.get('saved') else 'ğŸ“‹'
        time_str = time.strftime('%m-%d %H:%M', time.localtime(item.get('created_at', 0)))
        
        table_data.append([
            item.get('type', 'unknown'),
            item.get('name', 'unnamed'),
            time_str,
            status_icon,
            saved_icon
        ])

    put_table(table_data)


# ============================================================================
# ä» ai_code_creator å¯¼å…¥åˆ›å»ºå™¨
# ============================================================================

# å¯¼å…¥å®Œæ•´çš„åˆ›å»ºå™¨åŠŸèƒ½
from .ai_code_creator import (
    show_datasource_creator,
    show_strategy_creator,
    show_task_creator,
    add_to_recent_creations,
)


# ============================================================================
# å¯¼å‡º
# ============================================================================

__all__ = [
    'show_ai_studio',
    'show_quick_chat_gen',
    'show_quick_code_gen',
    'show_creation_center',
    'show_generation_center',
    'show_creation_history',
]
